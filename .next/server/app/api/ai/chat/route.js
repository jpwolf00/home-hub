"use strict";(()=>{var e={};e.id=76,e.ids=[76],e.modules={399:e=>{e.exports=require("next/dist/compiled/next-server/app-page.runtime.prod.js")},517:e=>{e.exports=require("next/dist/compiled/next-server/app-route.runtime.prod.js")},9374:(e,t,r)=>{r.r(t),r.d(t,{originalPathname:()=>g,patchFetch:()=>v,requestAsyncStorage:()=>d,routeModule:()=>l,serverHooks:()=>m,staticGenerationAsyncStorage:()=>h});var a={};r.r(a),r.d(a,{POST:()=>c});var o=r(9303),s=r(8716),n=r(670),i=r(7070);let p=process.env.OLLAMA_BASE_URL||"http://192.168.85.50:11434",u=process.env.OLLAMA_MODEL||"qwen3:14b";async function c(e){try{let{messages:t}=await e.json(),r=t.map(e=>({role:"user"===e.role?"user":"assistant",content:e.content})),a=await fetch(`${p}/api/chat`,{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({model:u,messages:r,stream:!1})});if(!a.ok)throw Error(`Ollama error: ${a.status}`);let o=await a.json();return i.NextResponse.json({message:{role:"assistant",content:o.message?.content||"No response"}})}catch(e){return console.error("AI Chat error:",e),i.NextResponse.json({error:"Failed to get AI response"},{status:500})}}let l=new o.AppRouteRouteModule({definition:{kind:s.x.APP_ROUTE,page:"/api/ai/chat/route",pathname:"/api/ai/chat",filename:"route",bundlePath:"app/api/ai/chat/route"},resolvedPagePath:"/home/jpwolf00/.openclaw/workspace/home-hub/src/app/api/ai/chat/route.ts",nextConfigOutput:"standalone",userland:a}),{requestAsyncStorage:d,staticGenerationAsyncStorage:h,serverHooks:m}=l,g="/api/ai/chat/route";function v(){return(0,n.patchFetch)({serverHooks:m,staticGenerationAsyncStorage:h})}}};var t=require("../../../../webpack-runtime.js");t.C(e);var r=e=>t(t.s=e),a=t.X(0,[276,972],()=>r(9374));module.exports=a})();